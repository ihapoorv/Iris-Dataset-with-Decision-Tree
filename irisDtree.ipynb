{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository. It includes three iris species that are Iris-setosa, Iris-versicolor and Iris-virginica with 50 samples each, as well as some properties about each flower.\n",
    "\n",
    "\n",
    "**Research Work**<br>\n",
    "To classify the species of the iris flower based on sepal and petal length/width.\n",
    "\n",
    "**Hypothesis**\n",
    "\n",
    "**$H_{0}$:-** There is no statistical relationship between the petal length and petal width of the iris flowers.<br>\n",
    "**$H_{1}$:-** There is statistical relationship between the petal length and petal width of the iris flowers.\n",
    "\n",
    "**Assumptions**\n",
    "+ At the beginning, the whole training set is considered as the root.\n",
    "+ Feature values are preferred to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
    "+ Records are distributed recursively on the basis of attribute values.\n",
    "+ Order to placing attributes as root or internal node of the tree is done by using some statistical approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import statistics as s\n",
    "import scipy.stats as ss\n",
    "from sklearn.datasets import load_iris\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignoring the warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "data = pd.read_csv(\"C:/Users/apoorv.srivastava/Downloads/datasets 2/datasets/Iris/iris.data.txt\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "features = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "target = pd.Categorical.from_codes(iris.target, iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out the features names\n",
    "features.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming column names\n",
    "features.rename(columns = {'sepal length (cm)':'SepalLength', \n",
    "                           'sepal width (cm)':'SepalWidth', \n",
    "                           'petal length (cm)':'PetalLength', \n",
    "                           'petal width (cm)':'PetalWidth'},\n",
    "               inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          5.1         3.5          1.4         0.2\n",
       "1          4.9         3.0          1.4         0.2\n",
       "2          4.7         3.2          1.3         0.2\n",
       "3          4.6         3.1          1.5         0.2\n",
       "4          5.0         3.6          1.4         0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValue =  3.883537681963073e-43\n",
      "Rejecting Null Hypothesis and Accepting Alternative Hyposthesis\n"
     ]
    }
   ],
   "source": [
    "#proving hypothesis\n",
    "ttest,pVal = ss.ttest_ind(features.PetalLength, features.PetalWidth)\n",
    "print(\"pValue = \",pVal)\n",
    "if pVal < 0.05:\n",
    "    print(\"Rejecting Null Hypothesis and Accepting Alternative Hyposthesis\")\n",
    "else:\n",
    "    print(\"Accepting Null Hypothesis and Rejecting Alternative Hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setosa, setosa, setosa, setosa, setosa, ..., virginica, virginica, virginica, virginica, virginica]\n",
      "Length: 150\n",
      "Categories (3, object): [setosa, versicolor, virginica]\n"
     ]
    }
   ],
   "source": [
    "#Printing the categorical variable\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion-1**<br>\n",
    "As the above cell depict that the values are categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree** builds classification or regression models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. It uses Entropy and Information Gain to construct a decision tree.<br>\n",
    "**Entropy:**<br>\n",
    "Entropy controls how a Decision Tree decides to split the data. It actually effects how a Decision Tree draws its boundaries.<br>\n",
    "**Information Gain:**<br>\n",
    "Information gain (IG) measures how much \"information\" a feature gives us about the class.<br>\n",
    "**Gini Index:**<br>\n",
    "The Gini index is a simple measure of the distribution of income across income percentiles in a population. A higher Gini index indicates greater inequality, with high income individuals receiving much larger percentages of the total income of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision trees can handle categorical data, we still encode the targets in terms of digits (i.e. setosa=0, versicolor=1, virginica=2) \n",
    "#in order to create a confusion matrix later. \n",
    "#pandas library provides a method for this.\n",
    "target = pd.get_dummies(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the performance of our model. Therefore setting a quarter of the data for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating and training the DecisionTreeClassifer.\n",
    "dtree = DecisionTreeClassifier()\n",
    "model = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting using our model\n",
    "y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a classification problem, we use a confusion matrix to get the accuracy of our model.\n",
    "species = np.array(y_test).argmax(axis=1)\n",
    "predictions = np.array(y_pred).argmax(axis=1)\n",
    "confusion_matrix(species, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion-2**<br>\n",
    "As the above cell depict that our decision tree model predicted 37/38 species correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Model Accuracy is 97.36842105263158\n"
     ]
    }
   ],
   "source": [
    "dtaccuracy=metrics.accuracy_score(y_pred,y_test)\n",
    "print(\"Decission Tree Model Accuracy is {}\".format(dtaccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Conclusions**\n",
    "+ Accuracy of our Decision Tree model is 97.36%.\n",
    "+ Hypothesis Testing (t test) proved that there is statistical relationship between the two variables.\n",
    "+ Confusion matrix depicts that only one species is wrongly predicted.\n",
    "+ Our decision tree model gives the promising results.\n",
    "+ In my last repo I applied Logistic Regression on the same data and got 91.11% accuracy which is less than Dtree Accuracy.\n",
    "+ Further we will check for some different algorithms such as SVM.\n",
    "+ After that we will get to know which model is giving the higher accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
